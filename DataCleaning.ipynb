{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sqlalchemy\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from scipy.stats import kurtosis\n",
    "from datacleaner import data_cleaning \n",
    "\n",
    "import time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df_data,remove_cols,missing_thres,df_catOrNum,standardisation_needed,save_data_scoring,target,model_name):\n",
    "    \n",
    "\n",
    "    for i in remove_cols:\n",
    "        try:\n",
    "            del df_data[i]\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    \n",
    "    def show_missing(data):\n",
    "        missing = data.columns[data.isnull().any()].tolist()\n",
    "        missing_series=(data[missing].isnull().sum())\n",
    "        missing_df=pd.DataFrame({'col_name':missing_series.index, 'missing_count':missing_series.values})\n",
    "        missing_df.sort_values(by='missing_count',ascending=False, inplace=True)\n",
    "        return missing_df\n",
    "\n",
    "\n",
    "    features_all_missing = df_data.loc[:,df_data.notnull().sum()==0].columns\n",
    "    df_data.drop(features_all_missing,axis=1,inplace=True)\n",
    "    #len(features_all_missing)\n",
    "    df_missing=show_missing(df_data)\n",
    "    \n",
    "    def find_cols_with_missing_thres(df_missing,df_data,thres):\n",
    "        df_missing=df_missing[df_missing['missing_count']>= thres*len(df_data)]\n",
    "        cols=df_missing['col_name'].tolist()\n",
    "        return cols\n",
    "    cols_to_drop=find_cols_with_missing_thres(df_missing,df_data,missing_thres)\n",
    "    \n",
    "    df_data.drop(cols_to_drop,axis=1,inplace=True)\n",
    "    \n",
    "    features=list(df_data)\n",
    "    \n",
    "    df_catOrNum = df_catOrNum[df_catOrNum.Feature.isin(features)]\n",
    "    \n",
    "    features_categorical=df_catOrNum[df_catOrNum['Feature_type']=='Categorical']['Feature'].tolist()\n",
    "    features_numerical=df_catOrNum[df_catOrNum['Feature_type']=='Numerical']['Feature'].tolist()\n",
    "    \n",
    "    X=df_data.copy()\n",
    "\n",
    "    try:\n",
    "        for f in features_categorical:\n",
    "            X.loc[X[f].isnull(),f] = 'ND'\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_missing=show_missing(X)\n",
    "\n",
    "    try:\n",
    "        for f in features_numerical:\n",
    "            X.loc[X[f].isin([\"C\",\"M\",\"H\",\"T\",\"__\",\"\",\"P\",\"E\",\"F\",\"G\",\"K\",\"I\"]),f] = np.nan\n",
    "            X[f] = X[f].astype(float)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    features_all_missing1 = X.loc[:,X.notnull().sum()==0].columns\n",
    "    \n",
    "    X.drop(features_all_missing1,axis=1,inplace=True)\n",
    "\n",
    "    features_numerical=list(set(features_numerical)-set(features_all_missing1))\n",
    "    a = X[features_numerical].isnull().sum()\n",
    "    \n",
    "    dict_numerical_missing = {i:j for i,j in a.iteritems() if j>0}\n",
    "    features_numerical_missing = list(dict_numerical_missing.keys())\n",
    "    features_numerical_nonmissing = list(set(features_numerical)-set(features_numerical_missing))\n",
    "\n",
    "    imputer = Imputer(strategy=\"median\",axis=0)\n",
    "\n",
    "    try:\n",
    "        X_median = pd.DataFrame(imputer.fit_transform(X[features_numerical_missing])\n",
    "                         ,columns=[i+'_Median' for i in features_numerical_missing]\n",
    "                         ,index=X.index)\n",
    "\n",
    "        X = X.merge(X_median,left_index=True,right_index=True)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for f in features_numerical_missing:\n",
    "        X[f+'_Zero'] = X[f].fillna(0)\n",
    "        \n",
    "        \n",
    "    y = df_data[target]\n",
    "    del X[target]\n",
    "    dict_auc_bin = {i:0 for i in features_numerical_missing}\n",
    "    dict_auc_median = {i:0 for i in features_numerical_missing}\n",
    "    dict_auc_zero = {i:0 for i in features_numerical_missing}\n",
    "    dict_auc_countND = {i:0 for i in features_numerical_missing}\n",
    "    dict_auc_countBins = {i:0 for i in features_numerical_missing}\n",
    "    for count,i in enumerate(features_numerical_missing):\n",
    "        #print(str(count)+' out of '+str(len(features_numerical_missing)))\n",
    "        #X_temp_bin = pd.get_dummies(X[i+'_Bin'])\n",
    "        X_temp_median = X[i+'_Median']\n",
    "        X_temp_zero = X[i].fillna(0)\n",
    "        y_temp = y\n",
    "\n",
    "        #### median ####\n",
    "        clf = linear_model.LogisticRegression()\n",
    "        clf.fit(X_temp_median.values.reshape(-1, 1),y_temp)\n",
    "        y_score = list(map(lambda x: x[1],clf.predict_proba(X_temp_median.values.reshape(-1, 1))))\n",
    "        dict_auc_median[i] = roc_auc_score(y_temp,y_score)\n",
    "        #### zero ####\n",
    "        clf = linear_model.LogisticRegression()\n",
    "        clf.fit(X_temp_zero.values.reshape(-1, 1),y_temp)\n",
    "        y_score = list(map(lambda x: x[1],clf.predict_proba(X_temp_zero.values.reshape(-1, 1))))\n",
    "        dict_auc_zero[i] = roc_auc_score(y_temp,y_score)\n",
    "    df_auc = pd.DataFrame({'AUC_bin':dict_auc_bin,'AUC_median':dict_auc_median,\n",
    "                       'AUC_zero':dict_auc_zero,'NoMissing':dict_auc_countND,'NoBins':dict_auc_countBins}) \n",
    "    \n",
    "    df_auc['AUC_max'] = ['Median' if j>z else 'Zero' for j,z in zip(df_auc['AUC_median'],df_auc['AUC_zero'])]\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "        median_list = list(df_auc.loc[df_auc.AUC_max=='Median',:].index)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "        zero_list = list(df_auc.loc[df_auc.AUC_max=='Zero',:].index)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    #bin_list = list(df_auc.loc[df_auc.AUC_max=='Bin',:].index)\n",
    "    features_numerical_missing_filled = [i+'_Median' for i in median_list] + [i+'_Zero' for i in zero_list]\n",
    "    \n",
    "    median_series = X[median_list].median()\n",
    "    zeros = pd.Series({i:0 for i in zero_list})\n",
    "    \n",
    "    features=features_categorical + features_numerical_nonmissing + features_numerical_missing_filled\n",
    "    #features = features =list(X)\n",
    "\n",
    "    try:\n",
    "\n",
    "        X.loc[:,'ResidentInUKMonths_Bin5'] = pd.qcut(X.loc[:,'ResidentInUKMonths'],q=5,duplicates='drop').astype(\"object\")\n",
    "        del X['ResidentInUKMonths']\n",
    "\n",
    "        features.remove('ResidentInUKMonths')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    X_dummy = pd.get_dummies(X[features])\n",
    "    features_dummy = X_dummy.columns\n",
    "\n",
    "    features_dummy = X_dummy.columns\n",
    "    \n",
    "    \n",
    "    def removePerfectCollinearity(X,features):\n",
    "        rho = X[features].corr()\n",
    "        rho = rho.where(np.triu(np.ones(rho.shape)).astype(np.bool))\n",
    "        rho1 = rho.unstack()\n",
    "        rho2 = rho1.reset_index().rename(columns={0:'Corr'})\n",
    "        rho2 = rho2[rho2.level_0!=rho2.level_1].sort_values(by=['Corr','level_0','level_1'],ascending=False)\n",
    "        features_duplicate = rho2[rho2.Corr==1].level_1.drop_duplicates()\n",
    "        features_new = list(set(features) - set(features_duplicate))\n",
    "        return(features_new)\n",
    "\n",
    "    features_dummy = removePerfectCollinearity(X_dummy,features_dummy)\n",
    "\n",
    "    X_dummy = X_dummy[features_dummy]\n",
    "\n",
    "    X_dummy.filter(regex=\"^ResidentInUKMonths\").columns\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    '''clf = RandomForestClassifier(n_estimators=500,min_samples_leaf=20,random_state=123)\n",
    "    clf.fit(X_dummy,y)\n",
    "    df_feat_importance = pd.DataFrame(sorted(zip(clf.feature_importances_,X_dummy.columns),reverse=True))\n",
    "    df_feat_importance.columns = ['Importance','Feature']\n",
    "    df_feat_importance.sort_values(by='Importance',ascending=False,inplace=True)\n",
    "\n",
    "    features_filtered = list(df_feat_importance.loc[df_feat_importance.Importance>0,:].Feature.values)\n",
    "    '''\n",
    "\n",
    "    X_final = X_dummy#[features_filtered]\n",
    "\n",
    "   \n",
    "\n",
    "    features_numerical = X_final.dtypes[X_final.dtypes.isin([np.dtype('int64'),np.dtype('float64')])].index\n",
    "\n",
    "    a = X_final[features_numerical].apply(lambda x: pd.Series({'k':kurtosis(x),'nonNegative':all(x>=0)})).T\n",
    "    features_to_log = a.loc[(a.k>0)&(a.nonNegative),:].index\n",
    "\n",
    "\n",
    "\n",
    "    for f in features_to_log:\n",
    "        X_final.loc[:,f+'_log'] = np.log10(X_final.loc[:,f] + 1)\n",
    "    X_final.drop(features_to_log,axis=1,inplace=True)\n",
    "\n",
    "    a = X_final.nunique()\n",
    "    features_binary = a[a==2].index\n",
    "    features_nonbinary = list(set(X_final.columns)-set(features_binary))\n",
    "\n",
    "    standard_df = pd.concat([X_final[features_nonbinary].mean(),X_final[features_nonbinary].std()],axis=1,keys=['Mean','Std'])\n",
    "\n",
    "    if standardisation_needed ==1 :\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_final1 = pd.DataFrame(scaler.fit_transform(X_final[features_nonbinary]),columns=X_final[features_nonbinary].columns,index=X_final[features_nonbinary].index)\n",
    "        X_final2 = X_final[features_binary]\n",
    "        X_final = X_final1.merge(X_final2,right_index=True,left_index=True)\n",
    "\n",
    "    #X_final.to_csv('X_features_digital_EQ3_1.csv')\n",
    "\n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H_%M_%S')\n",
    "    st=str(st).replace(\" \", \"_\")\n",
    "\n",
    "    X_new=X_final.copy()\n",
    "    \n",
    "    df_median=pd.DataFrame({'orig_feature':median_series.index, 'mis_val_imp':median_series.values})\n",
    "    df_median['missImpute_Feature']=df_median['orig_feature'].astype(str)+'_Median'\n",
    "\n",
    "\n",
    "    df_zero=pd.DataFrame({'orig_feature':zeros.index, 'mis_val_imp':zeros.values})\n",
    "    df_zero['missImpute_Feature']=df_zero['orig_feature'].astype(str)+'_Zero'\n",
    "\n",
    "\n",
    "    if save_data_scoring==1:\n",
    "        pd.Series(features_to_log).to_csv('featuresToLog'+'_'+st+'_'+str(model_name)+'.csv')\n",
    "        df_median.append(df_zero).to_csv('fill_missing_feats_median_zero_series'+'_'+st+'_'+model_name+'.csv')\n",
    "        median_series.to_csv('fill_missing_feats_median'+'_'+st+'_'+model_name+'.csv')\n",
    "        zeros.to_csv('fill_missing_feats_zeros_series2_v2'+'_'+st+'_'+model_name+'.csv')\n",
    "        X_new.to_csv('CleanedData'+'_'+st+'_'+model_name+'.csv')\n",
    "    if save_data_scoring==1 and standardisation_needed ==1:\n",
    "\n",
    "        standard_df.to_csv('standardising'+'_'+st+'_'+model_name+'.csv')\n",
    "        \n",
    "        \n",
    "    return X_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
